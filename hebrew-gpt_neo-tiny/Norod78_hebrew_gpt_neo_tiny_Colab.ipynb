{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Norod78/hebrew-gpt_neo-tiny Colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNZyVeiDKLA4H+qms/kbh24",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Norod/hebrew-gpt_neo/blob/main/hebrew-gpt_neo-tiny/Norod78_hebrew_gpt_neo_tiny_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_juNPy1ur__",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28b58476-8ccb-4262-b28d-cc9b10375449"
      },
      "source": [
        "!pip install tokenizers==0.10.2 transformers==4.6.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tokenizers==0.10.2 in /usr/local/lib/python3.7/dist-packages (0.10.2)\n",
            "Requirement already satisfied: transformers==4.6.0 in /usr/local/lib/python3.7/dist-packages (4.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0) (4.0.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0) (0.0.45)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0) (20.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0) (1.19.5)\n",
            "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0) (0.0.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.6.0) (2019.12.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.6.0) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.6.0) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.6.0) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.6.0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.6.0) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.6.0) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.6.0) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUdput1KutsJ"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "  \n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Norod78/hebrew-gpt_neo-tiny\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"Norod78/hebrew-gpt_neo-tiny\", pad_token_id=tokenizer.eos_token_id)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAbUb8s1xFnG"
      },
      "source": [
        "prompt_text = \"אני אוהב שוקולד ועוגות\"\n",
        "max_len = 512\n",
        "sample_output_num = 3\n",
        "seed = 1000"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts2uZXYVxRI8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f8c8bec-c3ce-45c0-ecc2-8e26281735e8"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = 0 if torch.cuda.is_available()==False else torch.cuda.device_count()\n",
        "\n",
        "print(f\"device: {device}, n_gpu: {n_gpu}\")\n",
        "\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if n_gpu > 0:\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "encoded_prompt = tokenizer.encode(\n",
        "    prompt_text, add_special_tokens=False, return_tensors=\"pt\")\n",
        "\n",
        "encoded_prompt = encoded_prompt.to(device)\n",
        "\n",
        "if encoded_prompt.size()[-1] == 0:\n",
        "        input_ids = None\n",
        "else:\n",
        "        input_ids = encoded_prompt\n",
        "\n",
        "print(\"input_ids = \" + str(input_ids))\n",
        "\n",
        "if input_ids != None:\n",
        "  max_len += len(encoded_prompt[0])\n",
        "  if max_len > 1024:\n",
        "    max_len = 1024\n",
        "\n",
        "print(\"Updated max_len = \" + str(max_len))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device: cuda, n_gpu: 1\n",
            "input_ids = tensor([[ 2202, 22283, 10984,   631,  5679]], device='cuda:0')\n",
            "Updated max_len = 517\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKbH_r_2xUlT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2ba4c10-6e77-4eb3-86e5-36784c04d483"
      },
      "source": [
        "sample_outputs = model.generate(\n",
        "    input_ids,\n",
        "    do_sample=True, \n",
        "    max_length=max_len, \n",
        "    top_k=50, \n",
        "    top_p=0.95, \n",
        "    num_return_sequences=sample_output_num\n",
        ")\n",
        "\n",
        "print(100 * '-' + \"\\nOutput:\\n\" + 100 * '-')\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"\\n{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n",
        "  print(\"\\n\" + 100 * '-')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "0: אני אוהב שוקולד ועוגות שוקולד. אני רוצה שכולם יקנו לי את זה\".\n",
            "\"לצערי, יש אנשים שמבינים כמה חשוב זה להכין שוקולד. הם רוצים לראות משהו אחר, וזה לא קשור להפסדים. אני לא מנסה לעשות את זה, וזה חלק מהעניין\".\n",
            "\"לצערי, יש אנשים שמבינים כמה חשוב זה להכין שוקולד. הם רוצים לראות משהו אחר, וזה לא קשור להפסדים. אני לא מנסה לעשות את זה, וזה חלק מהעניין\".\n",
            "\"אני לא מנסה לעשות את זה, וזה חלק מהעניין. אני לא מנסה לעשות את זה, זה חלק מהעניין\"מה לעשות אני לא רוצה להיות אני\". \"אני צריך להיות מאושר בשביל עצמי. אין לי ספק שאני לא רוצה להיות אני. אני רוצה להיות אני, ולהסתכל עלי כאילו אני לא\".\n",
            "\"זה לא קשור להפסדים. אני מנסה לעשות את זה, וזה חלק מהעניין\"מה לעשות אני לא רוצה להיות אני\". \"אני רוצה להיות מאושר בשביל עצמי. לא. אני רוצה להיות מאושר בשביל עצמי. אין לי ספק שאני לא רוצה להיות אני\".\n",
            "\"אני לא רוצה להיות מאושר בשביל עצמי. אני רוצה להיות מאושר בשביל עצמי.\"אני רוצה להיות מאושר. אין לי ספק שאני רוצה להיות מאושר. לא. אין לי ספק שאני אוהב אותך\"אני לא רוצה להיות מאושר\".\"זה לא קשור להפסדים. אני רוצה להיות מאושר. אני רוצה להיות מאושר\".\"אין לי ספק שאני לא רוצה להיות אני. אין לי ספק שאני לא רוצה להיות אני.\"אני מקווה שלא תהפכו את זה לעוד יותר מסובך. אני לא רוצה להיות מאושר\".\"זה לא קשור להפסדים. אני רוצה להיות מאושר. אין לי ספק שאני לא רוצה להיות מאושר. אני רוצה להיות מאושר. אני רוצה להיות מאושר. אני רוצה להיות מאושר.\n",
            "לפרגן. לפעמים זה נכון, אבל לא תמיד נכון. לפעמים זה לא נכון.\"אני אוהב את זה וזה לא נכון שאני לא רוצה להיות אני. אני אוהב את זה וזה לא נכון שאני לא רוצה להיות אני\".\"אני אוהב אותך ואני לא רוצה להיות אני. אני רוצה להיות מאושר. זה לא משנה כמה אני שמח שאני יכול לעזור לאנשים. יש לי משפחה, אני חושב שיש לי מזל שלא הייתי מאושר אם הייתי מאושר\".\n",
            "\n",
            "אופיין: צבע כתום, גוון ירוק, גוף מלא, ורוד בהיר, תכלת בהיר, אדום חום, לבן, תכלת בהיר, צהוב, אפור בהיר, ירוק בהיר,\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "מחפשים\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "1: אני אוהב שוקולד ועוגות! אני תמיד אוהבת עוגות שוקולד עם שמנת. תמיד הייתי מנסה למצוא משהו אחר. מה שחיפשתי הוא מה הוא יעשה עם שוקולד מריר...\n",
            "חיפשתי משהו מתוק יותר, אך לא מצאתי. האמת היא שעד היום, כשאני חושבת על מה שאני חושבת על שוקולד, אני מתעלמת.\n",
            "אין לי מושג כמה היא לא נחמדה. תמיד אהבתי מוס שוקולד עם שוקולד. תמיד אהבתי מוס שוקולד עם שמנת. תמיד אהבתי את מה שאני א-לה הכי אוהבת.\n",
            "אני לא מצליחה למצוא בשבילי שוקולד. תמיד אהבתי מוס שוקולד עם שמנת. תמיד אהבתי מוס שוקולד עם חלב. תמיד אהבתי מוס שוקולד עם שומשום. תמיד אהבתי מוס שוקולד עם שומשום. תמיד אהבתי מוס שוקולד עם צימוקים. תמיד אהבתי מוס שוקולד עם וניל. תמיד אהבתי מוס שוקולד עם שוקולד עם לימון. תמיד אהבתי מוס שוקולד עם שומשום. תמיד אהבתי מוס שוקולד עם חלב עם גבינה. תמיד אהבתי מוס שוקולד עם צימוקים. תמיד אהבתי מוס שוקולד עם חלב עם יין. תמיד אהבתי מוס שוקולד עם שוקולד עם שקדים. תמיד אהבתי מוס שוקולד עם שומשום. תמיד אהבתי מוס שוקולד עם שמנת. תמיד אהבתי מוס שוקולד עם צימוקים. תמיד אהבתי מוס שוקולד עם שקדים. תמיד אהבתי מוס שוקולד עם שוקולד עם שקדים. תמיד אהבתי מוס שוקולד עם חלב. תמיד אהבתי מוס שוקולד עם שוקולד עם שמנת. תמיד אהבתי מוס שוקולד עם שוקולד עם שומשום. תמיד אהבתי מוס שוקולד עם שוקולד עם פירות. תמיד אהבתי מוס שוקולד עם שוקולד עם פירות. תמיד אהבתי מוס שוקולד עם שוקולד עם שומשום. תמיד אהבתי מוס שוקולד עם שמנת. תמיד אהבתי מוס שוקולד עם קוקוס. תמיד אהבתי מוס שוקולד עם חלב עם תפוזים. תמיד אהבתי מוס שוקולד עם פירות. תמיד אהבתי מוס שוקולד עם תותים. תמיד אהבתי מוס שוקולד עם קוקוס. תמיד אהבתי מוס שוקולד עם שוקולד עם תותים. תמיד אהבתי מוס שוקולד עם פירות. תמיד אהבתי מוס שוקולד עם חלב עם אגוזים. תמיד אהבתי מוס שוקולד עם שקדים. תמיד אהבתי מוס שוקולד עם שומשום. תמיד אהבתי מוס שוקולד עם קינמון. תמיד אהבתי מוס שוקולד עם שומשום. תמיד אהבתי מוס שוקולד עם צימוקים. תמיד אהבתי מוס שוקולד עם תותים. תמיד אהבתי מוס שוקולד עם תותים. תמיד אהבתי מוס שוקולד עם קוקוס. תמיד אהבתי מוס שוקולד עם פירות. תמיד אהבתי מוס שוקולד עם פירות. תמיד אהבתי מוס שוקולד\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "2: אני אוהב שוקולד ועוגות.\n",
            "את הפיסטוקים הקטנים הללו לא חייבים לאכול. אני יודעת איך להכין את הפיסטוקים האלה. הם מתייבשים מהר מאוד והם מתוקים וטעים.\n",
            "אני לא רוצה להכניס לפיסטוקים את הסוכר המומס, כי הם טעימים יותר. יש בשוק את השמנת החמוצה, וזה נותן טעם מתוק. אני גם אוהבת שוקולד מריר מאוד.\n",
            "את הפיסטוקים הקטנים הללו לא חייבים לאכול. הם טעימים יותר. אין כאן שום צורך, והם מתוקים וטעים.\n",
            "\n",
            "את רוב מוצרי החברה ניתן להשיג במגוון חנויות, רשתות שיווק, בתי מרקחת, חנויות של אוכל מוכן, בתי מרקחת, בתי ספר לברמנים, בתי אבות, בתי אבות וחנויות לכנסים, בתי חולים, מכללות, אוניברסיטאות, מכללות, בתי מרקחת, בתי ספר לברמנים, בתי אבות וחנויות לכנסים, מכללות, בתי חולים, מכללות, בתי חולים, מכללות, מכללות, אוניברסיטאות, בתי אבות וחנויות לכנסים, מכללות, בתי אבות וחנויות לכנסים, מכללות, בתי אבות וחנויות לכנסים, מכללות, בתי אבות וחנויות לכנסים, מכללות, מכללות, בתי אבות וחנויות לכנסים, מכללות, בתי אבות וחנויות לכנסים, מכללות, מכללות, בתי אבות וחנויות לכנסים, מכללות, בתי אבות וחנויות לכנסים, מכללות, בתי אבות וחנויות לכנסים, מכללות, בתי אבות וחנויות לכנסים, מכללות, בתי אבות וחנויות לכנסים, מכללות, בתי אבות וחנויות לכנסים, מכללות, בתי אבות וחנויות לכנסים, מכללות, בתי אבות וחנויות לכנסים, מכללות, בתי אבות וחנויות לכנסים, מכללות, בתי אבות וחנויות לכנסים, מכללות, בתי אבות וחנויות לכנסים, מכללות, בתי אבות וחנויות לכנסים, מכללות, בתי אבות וחנויות לכנסים, מכללות, בתי אבות וחנויות לכנסים, מכללות, מכללות, בתי אבות וחנויות לכנסים, מכללות, מכללות, בתי אבות וחנויות לכנסים, מכללות, בתי אבות וחנויות לכנסים, מכללות, בתי אבות וחנויות לכנסים, מכללות, בתי אבות וחנויות לכנסים, מכללות, בתי אבות וחנויות לכנסים, מכללות, בתי אבות וחנויות לכנסים, מכללות, בתי אבות וחנויות לכנסים, מכללות, בתי אבות וחנויות לכנסים, מכללות, בתי אבות וחנויות לכנסים, מכללות, בתי אבות וחנויות לכנסים, מכללות,\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}